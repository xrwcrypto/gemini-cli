/**
 * @license
 * Copyright 2025 Google LLC
 * SPDX-License-Identifier: Apache-2.0
 */

import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import * as fs from 'node:fs';
import * as path from 'node:path';
import * as os from 'node:os';
import { Config } from '../../../config/config.js';
import { 
  FileOperationsMigrationConfig, 
  MigrationPhase, 
  MIGRATION_PRESETS 
} from './migration-config.js';
import { MigrationAwareToolRegistry } from './migration-tool-registry.js';
import { ConfigBasedRollbackController, RollbackCLI } from './config-based-rollback.js';

/**
 * Migration validation tests ensuring no breaking changes and data integrity
 */
describe('Migration Validation End-to-End Tests', () => {\n  let tempDir: string;\n  let testFiles: string[];\n  let originalConsoleLog: typeof console.log;\n  \n  beforeEach(async () => {\n    tempDir = fs.mkdtempSync(path.join(os.tmpdir(), 'migration-validation-'));\n    originalConsoleLog = console.log;\n    console.log = vi.fn();\n    \n    // Create test files with various scenarios\n    testFiles = await createTestFileScenarios(tempDir);\n  });\n  \n  afterEach(() => {\n    console.log = originalConsoleLog;\n    if (fs.existsSync(tempDir)) {\n      fs.rmSync(tempDir, { recursive: true, force: true });\n    }\n  });\n  \n  describe('Data Integrity Validation', () => {\n    it('should preserve file content integrity during migration', async () => {\n      const scenarios = [\n        { phase: MigrationPhase.DISABLED, description: 'Legacy tools only' },\n        { phase: MigrationPhase.ADAPTERS, description: 'Migration adapters' },\n        { phase: MigrationPhase.FULL, description: 'Full FileOperations' },\n      ];\n      \n      const testContent = 'Original test content that must be preserved';\n      const testFile = path.join(tempDir, 'integrity-test.txt');\n      \n      // Create original content checksums\n      const originalChecksums = new Map<string, string>();\n      for (const file of testFiles) {\n        const content = fs.readFileSync(file, 'utf-8');\n        originalChecksums.set(file, generateChecksum(content));\n      }\n      \n      // Test each migration phase\n      for (const scenario of scenarios) {\n        const migrationConfig: FileOperationsMigrationConfig = {\n          ...MIGRATION_PRESETS.DEVELOPMENT,\n          phase: scenario.phase,\n          rolloutPercentage: 100,\n        };\n        \n        const config = createTestConfig(tempDir, migrationConfig);\n        const registry = await config.getToolRegistry();\n        \n        // Test read operations don't modify content\n        const readTool = registry.getTool('ReadFileTool');\n        expect(readTool).toBeDefined();\n        \n        for (const file of testFiles) {\n          const result = await readTool!.execute({ path: file });\n          const currentChecksum = generateChecksum(result.content);\n          const originalChecksum = originalChecksums.get(file);\n          \n          expect(currentChecksum).toBe(originalChecksum);\n        }\n        \n        // Test write operations preserve intended content\n        fs.writeFileSync(testFile, testContent);\n        \n        const writeTool = registry.getTool('WriteFileTool');\n        expect(writeTool).toBeDefined();\n        \n        const modifiedContent = testContent + ' - modified';\n        await writeTool!.execute({ path: testFile, content: modifiedContent });\n        \n        const writtenContent = fs.readFileSync(testFile, 'utf-8');\n        expect(writtenContent).toBe(modifiedContent);\n        \n        console.log(`‚úì Data integrity preserved in ${scenario.description}`);\n      }\n    });\n    \n    it('should handle file permissions and metadata correctly', async () => {\n      const config = createTestConfig(tempDir, MIGRATION_PRESETS.DEVELOPMENT);\n      const registry = await config.getToolRegistry();\n      \n      // Create test file with specific permissions\n      const permissionTestFile = path.join(tempDir, 'permission-test.txt');\n      fs.writeFileSync(permissionTestFile, 'Permission test content');\n      fs.chmodSync(permissionTestFile, 0o644);\n      \n      const originalStats = fs.statSync(permissionTestFile);\n      \n      // Test read doesn't affect permissions\n      const readTool = registry.getTool('ReadFileTool');\n      await readTool!.execute({ path: permissionTestFile });\n      \n      const afterReadStats = fs.statSync(permissionTestFile);\n      expect(afterReadStats.mode).toBe(originalStats.mode);\n      expect(afterReadStats.size).toBe(originalStats.size);\n      \n      // Test write preserves permissions when content changes\n      const writeTool = registry.getTool('WriteFileTool');\n      await writeTool!.execute({ \n        path: permissionTestFile, \n        content: 'Updated permission test content' \n      });\n      \n      const afterWriteStats = fs.statSync(permissionTestFile);\n      expect(afterWriteStats.mode).toBe(originalStats.mode);\n    });\n    \n    it('should handle concurrent access without corruption', async () => {\n      const config = createTestConfig(tempDir, {\n        ...MIGRATION_PRESETS.DEVELOPMENT,\n        features: {\n          predictiveCaching: false,\n          parallelExecution: true,\n          transactionManagement: true,\n          securityHardening: true,\n          advancedAnalytics: false,\n        },\n      });\n      \n      const registry = await config.getToolRegistry();\n      const concurrentTestFile = path.join(tempDir, 'concurrent-test.txt');\n      \n      // Initialize file\n      fs.writeFileSync(concurrentTestFile, 'Initial content\\n');\n      \n      const readTool = registry.getTool('ReadFileTool');\n      const writeTool = registry.getTool('WriteFileTool');\n      \n      // Create concurrent operations\n      const operations = [];\n      \n      // Multiple concurrent reads\n      for (let i = 0; i < 10; i++) {\n        operations.push(\n          readTool!.execute({ path: concurrentTestFile })\n        );\n      }\n      \n      // Multiple concurrent writes (would fail in real scenario, testing safety)\n      for (let i = 0; i < 5; i++) {\n        operations.push(\n          writeTool!.execute({ \n            path: concurrentTestFile, \n            content: `Content update ${i}\\n` \n          })\n        );\n      }\n      \n      // Execute all operations\n      const results = await Promise.allSettled(operations);\n      \n      // Verify no corruption - file should have valid content\n      const finalContent = fs.readFileSync(concurrentTestFile, 'utf-8');\n      expect(finalContent).toBeTruthy();\n      expect(finalContent.length).toBeGreaterThan(0);\n      \n      // Count successful operations\n      const successful = results.filter(r => r.status === 'fulfilled').length;\n      const failed = results.filter(r => r.status === 'rejected').length;\n      \n      console.log(`Concurrent operations: ${successful} successful, ${failed} failed`);\n      expect(successful).toBeGreaterThan(0); // At least some should succeed\n    });\n  });\n  \n  describe('Backward Compatibility Validation', () => {\n    it('should maintain API compatibility across migration phases', async () => {\n      const apiTestCases = [\n        {\n          toolName: 'ReadFileTool',\n          method: 'execute',\n          params: { path: testFiles[0] },\n          expectedFields: ['content'],\n        },\n        {\n          toolName: 'WriteFileTool',\n          method: 'execute',\n          params: { \n            path: path.join(tempDir, 'api-test-write.txt'), \n            content: 'API test content' \n          },\n          expectedFields: ['success'],\n        },\n        {\n          toolName: 'GlobTool',\n          method: 'execute',\n          params: { pattern: '*.txt', path: tempDir },\n          expectedFields: ['files'],\n        },\n      ];\n      \n      const phases = [MigrationPhase.DISABLED, MigrationPhase.ADAPTERS, MigrationPhase.FULL];\n      \n      for (const phase of phases) {\n        const migrationConfig: FileOperationsMigrationConfig = {\n          ...MIGRATION_PRESETS.DEVELOPMENT,\n          phase,\n          rolloutPercentage: 100,\n        };\n        \n        const config = createTestConfig(tempDir, migrationConfig);\n        const registry = await config.getToolRegistry();\n        \n        for (const testCase of apiTestCases) {\n          const tool = registry.getTool(testCase.toolName);\n          expect(tool).toBeDefined();\n          \n          // Verify method exists\n          expect(typeof (tool as any)[testCase.method]).toBe('function');\n          \n          // Execute and verify response structure\n          const result = await (tool as any)[testCase.method](testCase.params);\n          \n          // Verify expected fields exist\n          for (const field of testCase.expectedFields) {\n            expect(result).toHaveProperty(field);\n          }\n          \n          console.log(`‚úì API compatibility maintained for ${testCase.toolName} in ${phase}`);\n        }\n      }\n    });\n    \n    it('should handle legacy configuration gracefully', async () => {\n      // Test with minimal migration config (backward compatibility)\n      const minimalConfig: Partial<FileOperationsMigrationConfig> = {\n        phase: MigrationPhase.ADAPTERS,\n      };\n      \n      const config = createTestConfig(tempDir, minimalConfig as FileOperationsMigrationConfig);\n      const registry = await config.getToolRegistry();\n      \n      // Should still work with defaults\n      expect(registry).toBeInstanceOf(MigrationAwareToolRegistry);\n      \n      const readTool = registry.getTool('ReadFileTool');\n      expect(readTool).toBeDefined();\n      \n      const result = await readTool!.execute({ path: testFiles[0] });\n      expect(result.content).toBeTruthy();\n    });\n    \n    it('should handle missing migration configuration', async () => {\n      // Test with no migration config at all\n      const config = createTestConfig(tempDir, undefined);\n      const registry = await config.getToolRegistry();\n      \n      // Should fall back to legacy behavior\n      const readTool = registry.getTool('ReadFileTool');\n      expect(readTool).toBeDefined();\n      \n      const result = await readTool!.execute({ path: testFiles[0] });\n      expect(result.content).toBeTruthy();\n    });\n  });\n  \n  describe('Security Validation', () => {\n    it('should prevent directory traversal attacks', async () => {\n      const config = createTestConfig(tempDir, MIGRATION_PRESETS.DEVELOPMENT);\n      const registry = await config.getToolRegistry();\n      \n      const readTool = registry.getTool('ReadFileTool');\n      \n      // Test various directory traversal attempts\n      const maliciousPaths = [\n        '../../../etc/passwd',\n        '..\\\\..\\\\..\\\\windows\\\\system32\\\\config\\\\sam',\n        tempDir + '/../../../etc/passwd',\n        path.join(tempDir, '..', '..', '..', 'etc', 'passwd'),\n      ];\n      \n      for (const maliciousPath of maliciousPaths) {\n        try {\n          await readTool!.execute({ path: maliciousPath });\n          // If we get here without error, verify we didn't actually read sensitive files\n          console.log(`Warning: Path ${maliciousPath} was allowed`);\n        } catch (error) {\n          // Expected - security measures should prevent access\n          expect(error).toBeDefined();\n        }\n      }\n    });\n    \n    it('should validate file size limits', async () => {\n      const config = createTestConfig(tempDir, MIGRATION_PRESETS.DEVELOPMENT);\n      const registry = await config.getToolRegistry();\n      \n      // Create a large file for testing\n      const largeFile = path.join(tempDir, 'large-file.txt');\n      const largeContent = 'x'.repeat(10 * 1024 * 1024); // 10MB\n      fs.writeFileSync(largeFile, largeContent);\n      \n      const readTool = registry.getTool('ReadFileTool');\n      \n      try {\n        const result = await readTool!.execute({ path: largeFile });\n        // If allowed, verify content is handled properly\n        expect(result.content.length).toBe(largeContent.length);\n      } catch (error) {\n        // Expected if size limits are enforced\n        console.log('Large file reading was restricted (expected)');\n      }\n    });\n    \n    it('should handle special characters and encoding safely', async () => {\n      const config = createTestConfig(tempDir, MIGRATION_PRESETS.DEVELOPMENT);\n      const registry = await config.getToolRegistry();\n      \n      // Test various encodings and special characters\n      const testCases = [\n        { name: 'utf8.txt', content: 'Hello ‰∏ñÁïå üåç' },\n        { name: 'special-chars.txt', content: '!@#$%^&*()_+-=[]{}|;:\",./<>?' },\n        { name: 'newlines.txt', content: 'Line 1\\nLine 2\\r\\nLine 3\\r' },\n        { name: 'unicode.txt', content: '\\u0048\\u0065\\u006C\\u006C\\u006F' },\n      ];\n      \n      const readTool = registry.getTool('ReadFileTool');\n      const writeTool = registry.getTool('WriteFileTool');\n      \n      for (const testCase of testCases) {\n        const filePath = path.join(tempDir, testCase.name);\n        \n        // Write with special content\n        await writeTool!.execute({ path: filePath, content: testCase.content });\n        \n        // Read back and verify\n        const result = await readTool!.execute({ path: filePath });\n        expect(result.content).toBe(testCase.content);\n      }\n    });\n  });\n  \n  describe('Migration State Consistency', () => {\n    it('should maintain consistent state during phase transitions', async () => {\n      const transitions = [\n        { from: MigrationPhase.DISABLED, to: MigrationPhase.ADAPTERS },\n        { from: MigrationPhase.ADAPTERS, to: MigrationPhase.FULL },\n        { from: MigrationPhase.FULL, to: MigrationPhase.ADAPTERS },\n        { from: MigrationPhase.ADAPTERS, to: MigrationPhase.DISABLED },\n      ];\n      \n      for (const transition of transitions) {\n        // Set up initial phase\n        const initialConfig: FileOperationsMigrationConfig = {\n          ...MIGRATION_PRESETS.DEVELOPMENT,\n          phase: transition.from,\n          rolloutPercentage: 50,\n        };\n        \n        const initialConfigObj = createTestConfig(tempDir, initialConfig);\n        const initialRegistry = await initialConfigObj.getToolRegistry();\n        \n        // Perform some operations in initial phase\n        const testFile = path.join(tempDir, `transition-test-${Date.now()}.txt`);\n        const writeTool = initialRegistry.getTool('WriteFileTool');\n        await writeTool!.execute({ path: testFile, content: 'Transition test content' });\n        \n        // Transition to new phase\n        const newConfig: FileOperationsMigrationConfig = {\n          ...initialConfig,\n          phase: transition.to,\n        };\n        \n        const newConfigObj = createTestConfig(tempDir, newConfig);\n        const newRegistry = await newConfigObj.getToolRegistry();\n        \n        // Verify operations still work in new phase\n        const readTool = newRegistry.getTool('ReadFileTool');\n        const result = await readTool!.execute({ path: testFile });\n        expect(result.content).toBe('Transition test content');\n        \n        console.log(`‚úì Transition ${transition.from} ‚Üí ${transition.to} successful`);\n      }\n    });\n    \n    it('should handle rollback state preservation', async () => {\n      const config = createTestConfig(tempDir, MIGRATION_PRESETS.DEVELOPMENT);\n      const registry = await config.getToolRegistry() as MigrationAwareToolRegistry;\n      \n      const migrationMetrics = registry.getMigrationMetrics();\n      const rollbackManager = new (await import('./rollback-manager.js')).RollbackManager(\n        config.getFileOperationsMigration(),\n        migrationMetrics,\n        new (await import('./usage-metrics.js')).UsageMetricsCollector(migrationMetrics)\n      );\n      \n      // Create some state\n      const testFile = path.join(tempDir, 'rollback-state-test.txt');\n      fs.writeFileSync(testFile, 'Original state');\n      \n      // Trigger rollback\n      const rollbackState = rollbackManager.triggerManualRollback(\n        'tool',\n        'ReadFileTool',\n        'Test state preservation'\n      );\n      \n      expect(rollbackState.isActive).toBe(true);\n      \n      // Modify file during rollback\n      fs.writeFileSync(testFile, 'Modified during rollback');\n      \n      // Revert rollback\n      const status = rollbackManager.getRollbackStatus();\n      const rollbackIds = Object.keys(status.activeRollbacks);\n      if (rollbackIds.length > 0) {\n        rollbackManager.revertRollback(rollbackIds[0]);\n      }\n      \n      // Verify file state is preserved\n      const finalContent = fs.readFileSync(testFile, 'utf-8');\n      expect(finalContent).toBe('Modified during rollback');\n    });\n  });\n  \n  describe('CLI Integration Validation', () => {\n    it('should handle CLI rollback commands correctly', async () => {\n      const config = createTestConfig(tempDir, MIGRATION_PRESETS.DEVELOPMENT);\n      const registry = await config.getToolRegistry() as MigrationAwareToolRegistry;\n      \n      const migrationMetrics = registry.getMigrationMetrics();\n      const rollbackManager = new (await import('./rollback-manager.js')).RollbackManager(\n        config.getFileOperationsMigration(),\n        migrationMetrics,\n        new (await import('./usage-metrics.js')).UsageMetricsCollector(migrationMetrics)\n      );\n      \n      const rollbackController = new ConfigBasedRollbackController(\n        rollbackManager,\n        (await import('./config-based-rollback.js')).ROLLBACK_POLICIES.balanced\n      );\n      \n      const rollbackCLI = new RollbackCLI(rollbackController);\n      \n      // Test emergency command\n      const emergencyResult = rollbackCLI.executeCommand('emergency', ['CLI test emergency']);\n      expect(emergencyResult).toBe(true);\n      \n      // Test checkpoint commands\n      const checkpointCreateResult = rollbackCLI.executeCommand('checkpoint', ['create', 'cli-test']);\n      expect(checkpointCreateResult).toBe(true);\n      \n      // Test commands generation\n      const commandsResult = rollbackCLI.executeCommand('commands', []);\n      expect(commandsResult).toBe(true);\n      \n      // Test documentation generation\n      const docsResult = rollbackCLI.executeCommand('docs', []);\n      expect(docsResult).toBe(true);\n      \n      // Test invalid command\n      const invalidResult = rollbackCLI.executeCommand('invalid', []);\n      expect(invalidResult).toBe(false);\n    });\n    \n    it('should validate configuration file watching', async () => {\n      const configPath = path.join(tempDir, 'test-settings.json');\n      \n      const config = createTestConfig(tempDir, MIGRATION_PRESETS.DEVELOPMENT);\n      const registry = await config.getToolRegistry() as MigrationAwareToolRegistry;\n      \n      const migrationMetrics = registry.getMigrationMetrics();\n      const rollbackManager = new (await import('./rollback-manager.js')).RollbackManager(\n        config.getFileOperationsMigration(),\n        migrationMetrics,\n        new (await import('./usage-metrics.js')).UsageMetricsCollector(migrationMetrics)\n      );\n      \n      const rollbackController = new ConfigBasedRollbackController(\n        rollbackManager,\n        (await import('./config-based-rollback.js')).ROLLBACK_POLICIES.conservative,\n        configPath\n      );\n      \n      // Enable configuration-based rollback\n      rollbackController.enableConfigBasedRollback(config.getFileOperationsMigration());\n      \n      // Create initial config file\n      const initialConfig = {\n        fileOperationsMigration: {\n          phase: 'adapters',\n          rolloutPercentage: 50,\n        },\n      };\n      fs.writeFileSync(configPath, JSON.stringify(initialConfig, null, 2));\n      \n      // Simulate config change by writing emergency rollback\n      const emergencyConfig = {\n        fileOperationsMigration: {\n          phase: 'emergency_disabled',\n          rolloutPercentage: 0,\n          emergency: {\n            rollback: true,\n            reason: 'Validation test emergency',\n          },\n        },\n      };\n      \n      fs.writeFileSync(configPath, JSON.stringify(emergencyConfig, null, 2));\n      \n      // Give some time for file watcher to react\n      await new Promise(resolve => setTimeout(resolve, 100));\n      \n      // Disable monitoring\n      rollbackController.disableConfigBasedRollback();\n      \n      // Verify configuration was processed\n      expect(fs.existsSync(configPath)).toBe(true);\n    });\n  });\n});\n\n// Helper functions\n\nfunction createTestConfig(\n  targetDir: string,\n  migrationConfig?: FileOperationsMigrationConfig\n): Config {\n  return new Config({\n    contentGeneratorConfig: {\n      model: 'test-model',\n      apiKey: 'test-key',\n    },\n    embeddingModel: 'test-embedding',\n    targetDir,\n    debugMode: false,\n    fileOperationsMigration: migrationConfig,\n  });\n}\n\nasync function createTestFileScenarios(baseDir: string): Promise<string[]> {\n  const scenarios = [\n    { name: 'simple.txt', content: 'Simple text content' },\n    { name: 'empty.txt', content: '' },\n    { name: 'large.txt', content: 'Large content\\n'.repeat(1000) },\n    { name: 'binary.dat', content: Buffer.from([0x00, 0x01, 0x02, 0xFF]).toString('binary') },\n    { name: 'unicode.txt', content: 'üöÄ Unicode test with √©mojis and √± characters' },\n    { name: 'multiline.txt', content: 'Line 1\\nLine 2\\nLine 3\\n' },\n    { name: 'json-test.json', content: JSON.stringify({ test: true, value: 123 }, null, 2) },\n    { name: 'code.js', content: 'console.log(\"Hello, world!\");\\n' },\n  ];\n  \n  const files: string[] = [];\n  \n  for (const scenario of scenarios) {\n    const filePath = path.join(baseDir, scenario.name);\n    fs.writeFileSync(filePath, scenario.content);\n    files.push(filePath);\n  }\n  \n  // Create subdirectory with files\n  const subDir = path.join(baseDir, 'subdir');\n  fs.mkdirSync(subDir);\n  \n  const subFile = path.join(subDir, 'nested.txt');\n  fs.writeFileSync(subFile, 'Nested file content');\n  files.push(subFile);\n  \n  return files;\n}\n\nfunction generateChecksum(content: string): string {\n  // Simple checksum for testing - in production would use crypto\n  let hash = 0;\n  for (let i = 0; i < content.length; i++) {\n    const char = content.charCodeAt(i);\n    hash = ((hash << 5) - hash) + char;\n    hash = hash & hash; // Convert to 32-bit integer\n  }\n  return hash.toString(36);\n}\n